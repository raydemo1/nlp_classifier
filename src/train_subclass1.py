import os
import json
import logging
from pathlib import Path
from sentence_transformers import SentenceTransformer, losses, InputExample
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import time

def setup_logging(log_dir="outputs/logs"):
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    log_file = Path(log_dir) / f"train_subclass1_{int(time.time())}.log"

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def load_dataset(path, logger=None):
    items = []
    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()
        for line in tqdm(lines, desc="åŠ è½½æ•°æ®é›†", unit="æ¡"):
            x = json.loads(line)
            if x.get("sub1"):
                items.append(x)
    if logger:
        logger.info(f"åŠ è½½äº† {len(items)} æ¡æœ‰æ•ˆçš„subclass1æ•°æ®")
    return items

def build_label_map(items, logger=None):
    labels = sorted(list({x["sub1"] for x in items}))
    label_map = {l: i for i, l in enumerate(labels)}
    if logger:
        logger.info(f"æ„å»ºäº† {len(label_map)} ä¸ªsubclass1æ ‡ç­¾: {list(labels)}")
    return label_map

def build_examples(items, label_map):
    ex = []
    for x in items:
        y = label_map[x["sub1"]]
        ex.append(InputExample(texts=[x["text"]], label=y))
    return ex

def train(input_path="outputs/dataset.jsonl", outdir="outputs/models/subclass1", batch_size=32, epochs=6, lr=2e-5, device=None):
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    logger.info("å¼€å§‹subclass1æ¨¡å‹è®­ç»ƒ")

    # åŠ è½½æ•°æ®
    items = load_dataset(input_path, logger)
    if not items:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
        return None

    # æ„å»ºæ ‡ç­¾æ˜ å°„
    label_map = build_label_map(items, logger)

    # æ£€æµ‹GPU
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"

    # è¾“å‡ºGPUä½¿ç”¨æƒ…å†µ
    if device == "cuda":
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3 if gpu_count > 0 else 0
        print(f"ğŸš€ ä½¿ç”¨GPUè®­ç»ƒ: {gpu_count}ä¸ªè®¾å¤‡, ä¸»è®¾å¤‡: {gpu_name}, æ˜¾å­˜: {gpu_memory:.1f}GB")
        logger.info(f"ä½¿ç”¨GPUè®­ç»ƒ: {gpu_count}ä¸ªè®¾å¤‡, ä¸»è®¾å¤‡: {gpu_name}, æ˜¾å­˜: {gpu_memory:.1f}GB")
    else:
        print("ğŸ’» ä½¿ç”¨CPUè®­ç»ƒ")
        logger.info("ä½¿ç”¨CPUè®­ç»ƒ")

    logger.info(f"è®­ç»ƒå‚æ•°: batch_size={batch_size}, epochs={epochs}, lr={lr}, device={device}")

    # åˆ›å»ºæ¨¡å‹
    logger.info("åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
    model = SentenceTransformer("shibing624/text2vec-base-chinese-nli", device=device)

    # æ„å»ºè®­ç»ƒæ•°æ®
    logger.info("æ„å»ºè®­ç»ƒæ ·æœ¬...")
    train_ex = build_examples(items, label_map)
    loader = DataLoader(train_ex, batch_size=batch_size, shuffle=True)

    # è®¾ç½®æŸå¤±å‡½æ•°
    logger.info("è®¾ç½®æŸå¤±å‡½æ•°...")
    loss = losses.SoftmaxLoss(
        model=model,
        sentence_embedding_dimension=model.get_sentence_embedding_dimension(),
        num_labels=len(label_map)
    )

    # è®­ç»ƒè®¾ç½®
    warmup = int(len(loader) * epochs * 0.1)
    logger.info(f"è®­ç»ƒè®¾ç½®: {len(loader)}ä¸ªbatch, warmup={warmup}æ­¥")

    # å¼€å§‹è®­ç»ƒ
    logger.info("å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()

    # æ·»åŠ è¿›åº¦æ¡çš„å›è°ƒå‡½æ•°
    class ProgressCallback:
        def __init__(self, total_epochs):
            self.pbar = tqdm(total=total_epochs, desc="è®­ç»ƒè¿›åº¦", unit="epoch")
            self.epoch = 0

        def __call__(self, score, epoch, steps):
            if epoch > self.epoch:
                self.epoch = epoch
                self.pbar.update(1)
                logger.info(f"Epoch {epoch}/{total_epochs} å®Œæˆ")

    total_steps = len(loader) * epochs
    logger.info(f"æ€»è®­ç»ƒæ­¥æ•°: {total_steps}")

    model.fit(
        train_objectives=[(loader, loss)],
        epochs=epochs,
        warmup_steps=warmup,
        output_path=outdir,
        callback=ProgressCallback(epochs)
    )

    training_time = time.time() - start_time
    logger.info(f"è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")

    # ä¿å­˜æ¨¡å‹
    logger.info("ä¿å­˜æ¨¡å‹...")
    Path(outdir).mkdir(parents=True, exist_ok=True)
    model.save(outdir)

    # ä¿å­˜æ ‡ç­¾æ˜ å°„
    with open(Path(outdir) / "labels.json", "w", encoding="utf-8") as f:
        json.dump(label_map, f, ensure_ascii=False)

    logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {outdir}")
    print(f"âœ… Subclass1æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œä¿å­˜åˆ°: {outdir}")
    return outdir

if __name__ == "__main__":
    train()
